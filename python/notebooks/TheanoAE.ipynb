{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano as th\n",
    "from theano import tensor as T\n",
    "from numpy import random as rng\n",
    " \n",
    "class AutoEncoder(object):\n",
    "    def __init__(self, X, hidden_size, activation_function,\n",
    "                 output_function):\n",
    "        #X is the data, an m x n numpy matrix\n",
    "        #where rows correspond to datapoints\n",
    "        #and columns correspond to features.\n",
    "        assert type(X) is np.ndarray\n",
    "        assert len(X.shape)==2\n",
    "        self.X=X\n",
    "        self.X=th.shared(name='X', value=np.asarray(self.X, \n",
    "                         dtype=th.config.floatX),borrow=True)\n",
    "        #The config.floatX and borrow=True stuff is to get this to run\n",
    "        #fast on the gpu. I recommend just doing this without thinking about\n",
    "        #it until you understand the code as a whole, then learning more\n",
    "        #about gpus and theano.\n",
    "        self.n = X.shape[1]\n",
    "        self.m = X.shape[0]\n",
    "        #Hidden_size is the number of neurons in the hidden layer, an int.\n",
    "        assert type(hidden_size) is int\n",
    "        assert hidden_size > 0\n",
    "        self.hidden_size=hidden_size\n",
    "        initial_W = np.asarray(rng.uniform(\n",
    "                 low=-4 * np.sqrt(6. / (self.hidden_size + self.n)),\n",
    "                 high=4 * np.sqrt(6. / (self.hidden_size + self.n)),\n",
    "                 size=(self.n, self.hidden_size)), dtype=th.config.floatX)\n",
    "        self.W = th.shared(value=initial_W, name='W', borrow=True)\n",
    "        self.b1 = th.shared(name='b1', value=np.zeros(shape=(self.hidden_size,),\n",
    "                            dtype=th.config.floatX),borrow=True)\n",
    "        self.b2 = th.shared(name='b2', value=np.zeros(shape=(self.n,),\n",
    "                            dtype=th.config.floatX),borrow=True)\n",
    "        self.activation_function=activation_function\n",
    "        self.output_function=output_function\n",
    "                     \n",
    "    def train(self, n_epochs=10000, mini_batch_size=1, learning_rate=0.1):\n",
    "        index = T.lscalar()\n",
    "        x=T.matrix('x')\n",
    "        params = [self.W, self.b1, self.b2]\n",
    "        hidden = self.activation_function(T.dot(x, self.W)+self.b1)\n",
    "        output = T.dot(hidden,T.transpose(self.W))+self.b2\n",
    "        output = self.output_function(output)\n",
    "         \n",
    "        #Use cross-entropy loss.\n",
    "        L = -T.sum(x*T.log(output) + (1-x)*T.log(1-output), axis=1)\n",
    "        cost=L.mean()       \n",
    "        updates=[]\n",
    "         \n",
    "        #Return gradient with respect to W, b1, b2.\n",
    "        gparams = T.grad(cost,params)\n",
    "         \n",
    "        #Create a list of 2 tuples for updates.\n",
    "        for param, gparam in zip(params, gparams):\n",
    "            updates.append((param, param-learning_rate*gparam))\n",
    "         \n",
    "        #Train given a mini-batch of the data.\n",
    "        train = th.function(inputs=[index], outputs=[cost], updates=updates,\n",
    "                            givens={x:self.X[index:index+mini_batch_size,:]})\n",
    "                             \n",
    " \n",
    "        import time\n",
    "        start_time = time.clock()\n",
    "        for epoch in xrange(n_epochs):\n",
    "            #print \"Epoch:\",epoch\n",
    "            for row in xrange(0,self.m, mini_batch_size):\n",
    "                train(row)\n",
    "        end_time = time.clock()\n",
    "        print \"Average time per epoch=\", (end_time-start_time)/n_epochs\n",
    "        \n",
    "     \n",
    "    def get_weights(self):\n",
    "        return [self.W.get_value(), self.b1.get_value(), self.b2.get_value()]         \n",
    "               \n",
    "    def get_hidden(self,data):\n",
    "        x=T.dmatrix('x')\n",
    "        hidden = self.activation_function(T.dot(x,self.W)+self.b1)\n",
    "        transformed_data = th.function(inputs=[x], outputs=hidden)\n",
    "        return transformed_data(data)  \n",
    "    \n",
    "    def get_output(self,data):\n",
    "        y = T.dmatrix('y')\n",
    "        output = T.dot(y,T.transpose(self.W))+self.b2\n",
    "        reconstructed_data = th.function(inputs=[y], outputs=output)\n",
    "        return reconstructed_data(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def m_test(data):\n",
    "    X=data\n",
    "    activation_function = T.nnet.sigmoid\n",
    "    output_function=activation_function\n",
    "    hidden_features = 9\n",
    "    A = AutoEncoder(X, hidden_features, activation_function, output_function)\n",
    "    A.train()\n",
    "    W=np.transpose(A.get_weights()[0])\n",
    "    ####################################################\n",
    "    Y = A.get_hidden(X)\n",
    "    Z = A.get_output(Y)\n",
    "    ####################################################\n",
    "    print X\n",
    "    print \"##############################bellow is a compressed data##################################\"\n",
    "    print Y\n",
    "    print \"##############################bellow is a reconstructed data##################################\"\n",
    "    print Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(177, 14)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "#data = np.array([[1,2,5,3,4,5,6,9,8,7,4,5,6,9,8,7],[2,3,1,6,9,8,3,2,6,5,4,5,6,9,8,7],[1,2,5,8,9,6,4,7,5,3,4,5,6,9,8,7],[1,2,5,3,9,6,4,7,5,3,4,5,6,9,8,7],[1,2,5,1,9,6,4,7,5,3,1,2,5,3,9,6],[1,2,5,8,9,6,4,7,5,3,4,5,6,9,8,7],[1,2,9,8,9,6,4,7,5,3,6,4,7,5,3,4],[1,2,7,6,9,6,6,4,7,5,3,4,4,7,5,3],[1,2,5,8,9,6,4,7,5,3,4,5,6,9,8,7],[1,4,5,6,9,8,7,2,3,8,9,6,4,7,5,3]],dtype='f4')\n",
    "data = pd.read_csv(open('/home/melvin/Documents/mellvin 15.04/Deep-Learning-Algoringms/wine.data'))\n",
    "columns = ['class','alcohol','malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', \n",
    "           'nonflavanoid phenols', 'proanthocyanins',  'color_intensity', 'hue', 'od_of_diluted_wines', 'proline']\n",
    "data.columns = columns\n",
    "class_coloumns = columns[1:]\n",
    "X = data[class_coloumns].values\n",
    "Y =  data[columns[0]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size=0.33, random_state=42)\n",
    "X_train = np.array(X_train)\n",
    "print data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Scaling features to a range\n",
    "from sklearn import preprocessing\n",
    "X_train = np.array(X)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
    "X_train = X_train_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time per epoch= 0.0185246533\n",
      "[[ 0.57105263  0.2055336   0.4171123  ...,  0.46341463  0.78021978\n",
      "   0.55064194]\n",
      " [ 0.56052632  0.3201581   0.70053476 ...,  0.44715447  0.6959707\n",
      "   0.64693295]\n",
      " [ 0.87894737  0.23913043  0.60962567 ...,  0.30894309  0.7985348\n",
      "   0.85734665]\n",
      " ..., \n",
      " [ 0.58947368  0.69960474  0.48128342 ...,  0.08943089  0.10622711\n",
      "   0.39728959]\n",
      " [ 0.56315789  0.36561265  0.54010695 ...,  0.09756098  0.12820513\n",
      "   0.40085592]\n",
      " [ 0.81578947  0.66403162  0.73796791 ...,  0.10569106  0.12087912\n",
      "   0.20114123]]\n",
      "##############################bellow is a compressed data##################################\n",
      "[[ 0.47696699  0.08290706  0.23256226 ...,  0.34196205  0.90223357\n",
      "   0.61060427]\n",
      " [ 0.2638022   0.35229359  0.36509699 ...,  0.24597859  0.79024686\n",
      "   0.91183548]\n",
      " [ 0.2279911   0.14728996  0.17314868 ...,  0.05112143  0.83694499\n",
      "   0.78140579]\n",
      " ..., \n",
      " [ 0.2223606   0.87323556  0.27617897 ...,  0.76199743  0.26348749\n",
      "   0.16200281]\n",
      " [ 0.50852334  0.84322933  0.47654057 ...,  0.74495593  0.31982094\n",
      "   0.16764343]\n",
      " [ 0.42259175  0.86254575  0.3643282  ...,  0.47543392  0.0546973\n",
      "   0.25932743]]\n",
      "##############################bellow is a reconstructed data##################################\n",
      "[[ 0.57268462 -1.32319799 -0.61711607 ..., -0.04645937  0.91152984\n",
      "   0.27509086]\n",
      " [ 0.24881317 -0.88104003  0.53535643 ..., -0.3338712   0.9763754\n",
      "   0.95235404]\n",
      " [ 1.31275229 -0.81213988  0.37960661 ..., -0.31752259  1.11323834\n",
      "   1.49380325]\n",
      " ..., \n",
      " [ 0.33129534  0.98206774  0.17899846 ..., -2.29386707 -2.29956643\n",
      "  -0.50590386]\n",
      " [ 0.17472866 -0.49235958  0.32538249 ..., -1.68681653 -2.54855083\n",
      "  -0.38001074]\n",
      " [ 1.13739895  0.73503834  0.88085327 ..., -1.90454439 -1.56471285\n",
      "  -0.94517559]]\n"
     ]
    }
   ],
   "source": [
    "m_test(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
